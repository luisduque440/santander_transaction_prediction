{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of pickled pipelines\n",
    "Notice that `feature_importance.ipynb` was used to generate the file `feature_importance.csv` which ranks the importance of the features according to several metrics. \n",
    "\n",
    "Our goal is to implement the following pipelines using all, top20, top50, top100 and top150 features\n",
    "* Pipeline 1: Logistic regression (`o`)\n",
    "* Pipeline 2: Naive bayes\n",
    "* Pipeline 3: Random forest\n",
    "* Pipeline 4: XGBoost\n",
    "* Pipeline 5: Neural Network [To do]\n",
    "* Pipeline 6: SVM [To do]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from pipeline_utilities import create_base_pipeline\n",
    "from pipeline_utilities import pickle_pipeline\n",
    "from load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_ensemble, X_dropout, y, y_ensemble, y_dropout, X_train, y_train, train_csv, test_csv = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ensemble.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dropout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_40229</th>\n",
       "      <td>15.1432</td>\n",
       "      <td>-8.3687</td>\n",
       "      <td>12.2701</td>\n",
       "      <td>5.2384</td>\n",
       "      <td>11.4195</td>\n",
       "      <td>-10.7507</td>\n",
       "      <td>5.2407</td>\n",
       "      <td>12.4810</td>\n",
       "      <td>-0.9351</td>\n",
       "      <td>9.2720</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.6074</td>\n",
       "      <td>12.6048</td>\n",
       "      <td>3.7759</td>\n",
       "      <td>1.0008</td>\n",
       "      <td>16.2003</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>3.0516</td>\n",
       "      <td>8.2448</td>\n",
       "      <td>17.1630</td>\n",
       "      <td>13.4558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_163637</th>\n",
       "      <td>8.7181</td>\n",
       "      <td>0.7561</td>\n",
       "      <td>6.7905</td>\n",
       "      <td>7.0250</td>\n",
       "      <td>11.7998</td>\n",
       "      <td>-8.2966</td>\n",
       "      <td>6.0874</td>\n",
       "      <td>16.2614</td>\n",
       "      <td>-4.1693</td>\n",
       "      <td>5.9257</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4634</td>\n",
       "      <td>14.3199</td>\n",
       "      <td>2.6097</td>\n",
       "      <td>1.5432</td>\n",
       "      <td>20.3437</td>\n",
       "      <td>1.3267</td>\n",
       "      <td>-1.3356</td>\n",
       "      <td>9.5717</td>\n",
       "      <td>18.8114</td>\n",
       "      <td>-5.4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_95573</th>\n",
       "      <td>10.2345</td>\n",
       "      <td>7.8213</td>\n",
       "      <td>10.9351</td>\n",
       "      <td>4.2713</td>\n",
       "      <td>13.1699</td>\n",
       "      <td>2.2795</td>\n",
       "      <td>4.2074</td>\n",
       "      <td>19.5125</td>\n",
       "      <td>-0.7537</td>\n",
       "      <td>8.4267</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3495</td>\n",
       "      <td>1.9259</td>\n",
       "      <td>3.9075</td>\n",
       "      <td>9.2249</td>\n",
       "      <td>15.8319</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>1.2781</td>\n",
       "      <td>10.2785</td>\n",
       "      <td>13.8203</td>\n",
       "      <td>16.0938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_104667</th>\n",
       "      <td>12.1894</td>\n",
       "      <td>-1.2565</td>\n",
       "      <td>12.1256</td>\n",
       "      <td>6.4777</td>\n",
       "      <td>12.0089</td>\n",
       "      <td>2.0835</td>\n",
       "      <td>5.2671</td>\n",
       "      <td>14.7100</td>\n",
       "      <td>4.3011</td>\n",
       "      <td>7.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8735</td>\n",
       "      <td>9.2275</td>\n",
       "      <td>2.3494</td>\n",
       "      <td>9.6457</td>\n",
       "      <td>20.5058</td>\n",
       "      <td>-0.4216</td>\n",
       "      <td>-0.5202</td>\n",
       "      <td>7.4390</td>\n",
       "      <td>17.3920</td>\n",
       "      <td>-8.5830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_133952</th>\n",
       "      <td>16.3986</td>\n",
       "      <td>2.4849</td>\n",
       "      <td>13.4346</td>\n",
       "      <td>8.3635</td>\n",
       "      <td>12.5364</td>\n",
       "      <td>8.9614</td>\n",
       "      <td>4.9465</td>\n",
       "      <td>17.7668</td>\n",
       "      <td>1.0017</td>\n",
       "      <td>7.6885</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.8904</td>\n",
       "      <td>6.8405</td>\n",
       "      <td>3.3239</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>24.0276</td>\n",
       "      <td>-1.0515</td>\n",
       "      <td>5.6184</td>\n",
       "      <td>9.5720</td>\n",
       "      <td>13.1520</td>\n",
       "      <td>0.0644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                var_0   var_1    var_2   var_3    var_4    var_5   var_6  \\\n",
       "ID_code                                                                    \n",
       "train_40229   15.1432 -8.3687  12.2701  5.2384  11.4195 -10.7507  5.2407   \n",
       "train_163637   8.7181  0.7561   6.7905  7.0250  11.7998  -8.2966  6.0874   \n",
       "train_95573   10.2345  7.8213  10.9351  4.2713  13.1699   2.2795  4.2074   \n",
       "train_104667  12.1894 -1.2565  12.1256  6.4777  12.0089   2.0835  5.2671   \n",
       "train_133952  16.3986  2.4849  13.4346  8.3635  12.5364   8.9614  4.9465   \n",
       "\n",
       "                var_7   var_8   var_9   ...     var_190  var_191  var_192  \\\n",
       "ID_code                                 ...                                 \n",
       "train_40229   12.4810 -0.9351  9.2720   ...     -3.6074  12.6048   3.7759   \n",
       "train_163637  16.2614 -4.1693  5.9257   ...      2.4634  14.3199   2.6097   \n",
       "train_95573   19.5125 -0.7537  8.4267   ...      6.3495   1.9259   3.9075   \n",
       "train_104667  14.7100  4.3011  7.9739   ...      4.8735   9.2275   2.3494   \n",
       "train_133952  17.7668  1.0017  7.6885   ...     -1.8904   6.8405   3.3239   \n",
       "\n",
       "              var_193  var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "ID_code                                                                      \n",
       "train_40229    1.0008  16.2003   0.1415   3.0516   8.2448  17.1630  13.4558  \n",
       "train_163637   1.5432  20.3437   1.3267  -1.3356   9.5717  18.8114  -5.4102  \n",
       "train_95573    9.2249  15.8319   0.1480   1.2781  10.2785  13.8203  16.0938  \n",
       "train_104667   9.6457  20.5058  -0.4216  -0.5202   7.4390  17.3920  -8.5830  \n",
       "train_133952   0.2475  24.0276  -1.0515   5.6184   9.5720  13.1520   0.0644  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_40229</th>\n",
       "      <td>15.1432</td>\n",
       "      <td>-8.3687</td>\n",
       "      <td>12.2701</td>\n",
       "      <td>5.2384</td>\n",
       "      <td>11.4195</td>\n",
       "      <td>-10.7507</td>\n",
       "      <td>5.2407</td>\n",
       "      <td>12.4810</td>\n",
       "      <td>-0.9351</td>\n",
       "      <td>9.2720</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.6074</td>\n",
       "      <td>12.6048</td>\n",
       "      <td>3.7759</td>\n",
       "      <td>1.0008</td>\n",
       "      <td>16.2003</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>3.0516</td>\n",
       "      <td>8.2448</td>\n",
       "      <td>17.1630</td>\n",
       "      <td>13.4558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_163637</th>\n",
       "      <td>8.7181</td>\n",
       "      <td>0.7561</td>\n",
       "      <td>6.7905</td>\n",
       "      <td>7.0250</td>\n",
       "      <td>11.7998</td>\n",
       "      <td>-8.2966</td>\n",
       "      <td>6.0874</td>\n",
       "      <td>16.2614</td>\n",
       "      <td>-4.1693</td>\n",
       "      <td>5.9257</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4634</td>\n",
       "      <td>14.3199</td>\n",
       "      <td>2.6097</td>\n",
       "      <td>1.5432</td>\n",
       "      <td>20.3437</td>\n",
       "      <td>1.3267</td>\n",
       "      <td>-1.3356</td>\n",
       "      <td>9.5717</td>\n",
       "      <td>18.8114</td>\n",
       "      <td>-5.4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_95573</th>\n",
       "      <td>10.2345</td>\n",
       "      <td>7.8213</td>\n",
       "      <td>10.9351</td>\n",
       "      <td>4.2713</td>\n",
       "      <td>13.1699</td>\n",
       "      <td>2.2795</td>\n",
       "      <td>4.2074</td>\n",
       "      <td>19.5125</td>\n",
       "      <td>-0.7537</td>\n",
       "      <td>8.4267</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3495</td>\n",
       "      <td>1.9259</td>\n",
       "      <td>3.9075</td>\n",
       "      <td>9.2249</td>\n",
       "      <td>15.8319</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>1.2781</td>\n",
       "      <td>10.2785</td>\n",
       "      <td>13.8203</td>\n",
       "      <td>16.0938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_104667</th>\n",
       "      <td>12.1894</td>\n",
       "      <td>-1.2565</td>\n",
       "      <td>12.1256</td>\n",
       "      <td>6.4777</td>\n",
       "      <td>12.0089</td>\n",
       "      <td>2.0835</td>\n",
       "      <td>5.2671</td>\n",
       "      <td>14.7100</td>\n",
       "      <td>4.3011</td>\n",
       "      <td>7.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8735</td>\n",
       "      <td>9.2275</td>\n",
       "      <td>2.3494</td>\n",
       "      <td>9.6457</td>\n",
       "      <td>20.5058</td>\n",
       "      <td>-0.4216</td>\n",
       "      <td>-0.5202</td>\n",
       "      <td>7.4390</td>\n",
       "      <td>17.3920</td>\n",
       "      <td>-8.5830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_133952</th>\n",
       "      <td>16.3986</td>\n",
       "      <td>2.4849</td>\n",
       "      <td>13.4346</td>\n",
       "      <td>8.3635</td>\n",
       "      <td>12.5364</td>\n",
       "      <td>8.9614</td>\n",
       "      <td>4.9465</td>\n",
       "      <td>17.7668</td>\n",
       "      <td>1.0017</td>\n",
       "      <td>7.6885</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.8904</td>\n",
       "      <td>6.8405</td>\n",
       "      <td>3.3239</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>24.0276</td>\n",
       "      <td>-1.0515</td>\n",
       "      <td>5.6184</td>\n",
       "      <td>9.5720</td>\n",
       "      <td>13.1520</td>\n",
       "      <td>0.0644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                var_0   var_1    var_2   var_3    var_4    var_5   var_6  \\\n",
       "ID_code                                                                    \n",
       "train_40229   15.1432 -8.3687  12.2701  5.2384  11.4195 -10.7507  5.2407   \n",
       "train_163637   8.7181  0.7561   6.7905  7.0250  11.7998  -8.2966  6.0874   \n",
       "train_95573   10.2345  7.8213  10.9351  4.2713  13.1699   2.2795  4.2074   \n",
       "train_104667  12.1894 -1.2565  12.1256  6.4777  12.0089   2.0835  5.2671   \n",
       "train_133952  16.3986  2.4849  13.4346  8.3635  12.5364   8.9614  4.9465   \n",
       "\n",
       "                var_7   var_8   var_9   ...     var_190  var_191  var_192  \\\n",
       "ID_code                                 ...                                 \n",
       "train_40229   12.4810 -0.9351  9.2720   ...     -3.6074  12.6048   3.7759   \n",
       "train_163637  16.2614 -4.1693  5.9257   ...      2.4634  14.3199   2.6097   \n",
       "train_95573   19.5125 -0.7537  8.4267   ...      6.3495   1.9259   3.9075   \n",
       "train_104667  14.7100  4.3011  7.9739   ...      4.8735   9.2275   2.3494   \n",
       "train_133952  17.7668  1.0017  7.6885   ...     -1.8904   6.8405   3.3239   \n",
       "\n",
       "              var_193  var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "ID_code                                                                      \n",
       "train_40229    1.0008  16.2003   0.1415   3.0516   8.2448  17.1630  13.4558  \n",
       "train_163637   1.5432  20.3437   1.3267  -1.3356   9.5717  18.8114  -5.4102  \n",
       "train_95573    9.2249  15.8319   0.1480   1.2781  10.2785  13.8203  16.0938  \n",
       "train_104667   9.6457  20.5058  -0.4216  -0.5202   7.4390  17.3920  -8.5830  \n",
       "train_133952   0.2475  24.0276  -1.0515   5.6184   9.5720  13.1520   0.0644  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ensemble.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 'most relevant' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.read_csv('feature_importance.csv', index_col='feature').sort_values(by='average_rank')\n",
    "top10_features = list(feature_importance.index[:10])\n",
    "top20_features = list(feature_importance.index[:20])\n",
    "top50_features = list(feature_importance.index[:50])\n",
    "top100_features = list(feature_importance.index[:100])\n",
    "top150_features = list(feature_importance.index[:150])\n",
    "all_features = list(feature_importance.index)\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the pipelines we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipeline_descriptors = []\n",
    "\n",
    "\n",
    "\n",
    "# Linear support vector classifier\n",
    "#classifier = LinearSVC(random_state=0, tol=1e-5)\n",
    "#parameters = {}\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top10_features, 'linearsvm_top10.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top20_features, 'linearsvm_top20.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top50_features, 'linearsvm_top50.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top100_features, 'linearsvm_top100.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top150_features, 'linearsvm_top150.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, all_features, 'linearsvm_all.pkl'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Support vector machines\n",
    "#classifier = svm.SVC()\n",
    "#parameters = {'gamma':['scale']}\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top10_features, 'svm_top10.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top20_features, 'svm_top20.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top50_features, 'svm_top50.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top100_features, 'svm_top100.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top150_features, 'svm_top150.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, all_features, 'svm_all.pkl'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# linear classifier\n",
    "#classifier = LogisticRegression(penalty='l1')\n",
    "#parameters = {'C': 10**np.linspace(-4,-2, 20)}\n",
    "base_pipeline_descriptors.append((classifier, parameters, top10_features, 'linear_classifier_top10.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top20_features, 'linear_classifier_top20.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top50_features, 'linear_classifier_top50.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top100_features, 'linear_classifier_top100.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top150_features, 'linear_classifier_top150.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, all_features, 'linear_classifier_all.pkl'))\n",
    "\n",
    "\n",
    "\n",
    "# naive bayes\n",
    "#classifier = GaussianNB()\n",
    "#parameters = {}\n",
    "base_pipeline_descriptors.append((classifier, parameters, top10_features, 'naive_classifier_top10.pkl'))\n",
    "base_pipeline_descriptors.append((classifier, parameters, top20_features, 'naive_classifier_top20.pkl'))\n",
    "base_pipeline_descriptors.append((classifier, parameters, top50_features, 'naive_classifier_top50.pkl'))\n",
    "base_pipeline_descriptors.append((classifier, parameters, top100_features, 'naive_classifier_top100.pkl'))\n",
    "base_pipeline_descriptors.append((classifier, parameters, top150_features, 'naive_classifier_top150.pkl'))\n",
    "base_pipeline_descriptors.append((classifier, parameters, all_features, 'naive_classifier_all.pkl'))\n",
    "\n",
    "\n",
    "# random forest\n",
    "classifier = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_leaf' : [10, 100, 1000],\n",
    "    'n_estimators': [50, 100, 200],   \n",
    "    'max_features': ['sqrt']\n",
    "    \n",
    "}\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top10_features, 'forest_classifier_top10.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top20_features, 'forest_classifier_top20.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top50_features, 'forest_classifier_top50.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top100_features, 'forest_classifier_top100.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top150_features, 'forest_classifier_top150.pkl'))\n",
    "base_pipeline_descriptors.append((classifier, parameters, all_features, 'forest_classifier_all.pkl'))\n",
    "\n",
    "\n",
    "\n",
    "classifier = XGBClassifier()\n",
    "parameters = {\n",
    "    'max_depth':[5, 10, 20],   \n",
    "    'min_child_weight' : [10, 100, 1000], \n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'gamma': [0, 100]\n",
    "    \n",
    "}\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top10_features, 'xgboost_classifier_top10.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top20_features, 'xgboost_classifier_top20.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top50_features, 'xgboost_classifier_top50.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top100_features, 'xgboost_classifier_top100.pkl'))\n",
    "#base_pipeline_descriptors.append((classifier, parameters, top150_features, 'xgboost_classifier_top150.pkl'))\n",
    "base_pipeline_descriptors.append((classifier, parameters, all_features, 'xgboost_classifier_all.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation, training and pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main code\n",
    "for descriptor in base_pipeline_descriptors[-1:]:\n",
    "    classifier,parameters,features,filename = descriptor\n",
    "    base_pipeline = create_base_pipeline(descriptor, cv=2)\n",
    "    base_pipeline.fit(X,y)\n",
    "    pickle_pipeline(base_pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
